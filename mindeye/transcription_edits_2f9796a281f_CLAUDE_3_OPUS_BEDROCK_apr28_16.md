00:00:00 
 SPEAKER_00: What we would do today is go through a list of things that ~~**I**~~ ~~**think**~~ you guys should be thinking about as students that are headed for the workforce. ~~**I**~~ ~~**think**~~ The workforce is in for some significant change, and it is probably going to impact you the most. And so ~~**I**~~ ~~**wanted**~~ ~~**to**~~ explain why ~~**I**~~ ~~**think**~~ that's the case, and then also explain what ~~**I**~~ ~~**think**~~ you guys should do about it to give yourselves a competitive advantage early in your career, which also happens to be early in the AI era. This was after thinking about a little bit what ~~**I**~~ ~~**thought**~~ would be the most useful for students today. So ~~**I've**~~ titled this 10 super practical AI tips for current college students or how to stand out in a world of infinite AI interns. So my first couple of tips are really around just calibrating yourself to what's out there today. ~~**I'm**~~ ~~**sure**~~ you guys~~**,**~~ ~~**you**~~ ~~**know,**~~ have all used chat GPT. So forgive me if some of this is a little bit obvious or repetitive.

00:01:01 
 I speak to all different kinds of audiences and you would be amazed by how many people who are actually very smart, accomplished leaders have remarkably little curiosity about this technology and little awareness about just how far it has come already. So ~~**I**~~ ~~**always**~~ ~~**like**~~ ~~**to**~~ just set a little bit of a baseline by talking about where the technology is today. So my first recommendation in terms of~~**.**~~ what to do is understand current state of the art. This is a recommendation ~~**I**~~ ~~**give**~~ ~~**to**~~ just about everyone. And obviously a lot of ways to describe what the state of the art is. But the high level description that ~~**I**~~ ~~**tend**~~ ~~**to**~~ ~~**give**~~ is that AI is closing in on human expert performance ~~**on**~~ routine tasks.

00:01:50 
 And the word routine is really doing a lot of work. AI is getting really good at things where we know what good looks like. And so a few examples of that, we're starting to see, this is on a benchmark called NLU, which is a set of exams from the college and graduate school level from all disciplines. A typical human might get 35% of those questions right. An expert in the domain of interest gets 90% right. GPT-4 gets ~~**like**~~ 86% right. So it's closing in on human expert performance at these ~~**like**~~ discrete tasks where we know what the right answer is. Here's another one.

00:02:32 
 This is a paper out of Google, out of the MedPalm series. This is MedPalm 2 in particular. This is performance on medical licensing exams. So it's again, another one of these ~~**like**~~ test-like environments. To pass is 60% score on the licensing exam, which by the way, should give you some pause as to ~~**like**~~ just how accurate your human doctor is going to be on any given topic that you might have for them. MedPalm1 got to 67% correct and MedPalm2 blew past what you needed to pass and again closing in on that expert level 86%. This task is specifically medical question answering and here they asked a bunch of human doctors the same questions that they asked the AI. And then they asked human doctors to evaluate whether the AI answer was better or whether the human doctor answer was better.

00:03:27 
 The top chart are the good things. These are ~~**like**~~ the desirable traits, ~~**like**~~ better reflects the medical consensus, better reading comprehension, ~~**et**~~ ~~**cetera**~~. This is how often the AI was judged to have done a better job by human doctors as compared to other human doctors. So you see that overwhelmingly the AI is getting the higher marks. This is how often the human doctor was judged to have done a better job. And this is ~~**in**~~ ~~**between**~~ where it was considered to be a tie. ~~**then**~~ these are the bad things. So these are the things you don't want to have.

00:04:00 
 This is the only category that the AI lost, and that is basically on hallucinations. ~~**I'm**~~ ~~**sure**~~ ~~**you**~~ ~~**guys**~~ ~~**are**~~ ~~**all**~~ ~~**familiar**~~ ~~**with**~~ the problem of hallucinations. Here they describe it as more inaccurate or irrelevant information. And the AI did that more compared to the human doctor. But all the other bad things, the things that you don't want to happen in your medical question answering, the human doctors did more. So as judged by human doctors, the AI is beating human doctors on eight out of nine evaluated criteria. This is basically happening across the board. This is another version where they're doing diagnosis.

00:04:36 
 Again, it's beating humans. There's like just tons and tons of examples like this. ~~**I**~~ ~~**know**~~ there's a lot of CS students in the room. Coding challenges are another area where AIs are now outperforming the majority of people who participate in coding challenges. They'll enter AI into coding challenges alongside humans. It won't be the number one contestant, but it will be above average. These are pretty striking results. Now, one thing that the AIs are not really able to do yet, or at least very infrequently, is come up with genuinely new, really high quality ideas.

00:05:14 
 So I call these eureka moments.  And ~~**I**~~ ~~**would**~~ ~~**say**~~, ~~**I**~~ ~~**used**~~ ~~**to**~~ ~~**say**~~ there were no Eureka moments coming from AI. Now we've started to see a few of them. ~~**So**~~ ~~**I**~~ ~~**now**~~ ~~**say**~~ there are precious few Eureka moments. Here's one example of a Eureka moment. This is actually from a paper called Eureka. Oddly enough, ~~**I**~~ ~~**used**~~ ~~**to**~~ ~~**say**~~ ~~**that**~~, and then they titled the paper Eureka. ~~**So**~~ ~~**it**~~ ~~**was**~~ ~~**like**~~ a very ~~**sort**~~ ~~**of**~~ meta thing.

00:05:35 
 I was like, wow, they're reading my minds here. The task in this case, is writing a reward function for a robot to learn how to do a certain task. So to unpack~~**,**~~ that means if you're trying to do reinforcement learning to teach a robot to do a task, you need a reward function to evaluate how well it's doing on the task so that you can then train it to maximize that reward. ~~**A**~~ ~~**problem,**~~ ~~**though,**~~ is at the beginning, when the robot is just fumbling around and making very little progress, you have the problem of what's called sparse reward. So that is to say, if the robot is coming nowhere close, then it doesn't get any reward, then it doesn't have anything to learn from~~**,**~~ ~~**right**~~? It's so far off that we can't even identify~~**,**~~ ~~**oh,**~~ that was good, do more of that. It's just totally fumbling and flailing around. This is actually why a couple years ago, OpenAI had a project where they were going to try to get AIs to browse the web, and they were going to try to do this reinforcement learning, but they abandoned that project because they found that ~~**basically**~~ it was making no progress.

00:06:32 
 It was getting no reward, and so it had nothing to learn from. So when you're doing a project like this with robotics, you have to oftentimes write a custom reward function. So that is to say, ~~**okay**~~, we know that you can't, in this case, it's like a robot's trying to twirl a pencil in its hand. ~~**Now**~~ ~~**robot**~~ ~~**starts**~~ ~~**no**~~ ~~**ability**~~ ~~**to**~~ ~~**do**~~ ~~**that**~~ ~~**and**~~ ~~**it's**~~ ~~**not**~~ ~~**coming**~~ ~~**close**~~, ~~**right**~~? So you need a reward function to say, to at least proxy, to try to give some sense of ~~**like**~~, how can we detect even ~~**like**~~ the flicker of you getting close so we can reward that so we can hopefully bootstrap you into learning this task. You might, if you were to sit down and try to come up with a custom reward function, you might think ~~**like**~~ maybe angular momentum around a certain axis of the pen or whatever, it could be ~~**like**~~ a leading indicator of possibly this is headed in the right direction. ~~**It**~~ ~~**turns**~~ ~~**out**~~, ~~**and**~~ so humans do this, ~~**right**~~? This is ~~**like**~~ how it's done in robotics.

00:07:23 
 Like humans will sit there and try to think what would be close and I'll write a reward function for this. GPT-4 is actually a lot better at writing reward functions for these tasks than humans are. And this is something that really only experts do~~**,**~~ ~~**right**~~? ~~**Like**~~ you don't have a lot of amateur reward functions. If you go approach a person on the street and say, Hey, can you write a reward function ~~**with**~~ this robot? They'll just look at you. ~~**Like**~~, I have no idea what you're even talking about. So it's not~~**,**~~ you can't even compare to an average person.

00:07:48 
 This is all. compared to specialized people who ~~**like**~~ have expert or at least specialized skills. And GPT-4 is beating them and coming up with better reward functions, better able to train the robots. But you still see ~~**very**~~ few of these things where the robot is outperforming genuinely expert people at ~~**like**~~ new novel tasks. So that's important just to understand what ~~**can**~~ AI ~~**do**~~ today. Again, to summarize, it is closing in on expert performance on routine tasks, but still ~~**precious**~~ few eureka moments, ~~**precious**~~ few genuinely new insights coming out of AI systems. When they ~~**do**~~ happen, they make news because they're still ~~**very**~~ rare. ~~**Okay**~~.

00:08:31 
 Next understand the tail of the cognitive tape. This is why is it happening that way? And there's a lot of dimensions to this. I'll try to go through it quickly. I break down all these different aspects of cognition and then just give each a human expert and an AI a score. ~~**Again**~~, ~~**this**~~ ~~**is**~~ ~~**not**~~ ~~**an**~~ ~~**average**~~ ~~**person**~~. ~~**This**~~ ~~**is**~~ ~~**an**~~ ~~**expert**~~ ~~**that**~~ ~~**I'm**~~ ~~**evaluating**~~ ~~**here**~~. So for breadth, obviously AI has a huge advantage over humans.

00:08:55 
 It has read the whole internet,~~**right**~~? It's read all the books. It can score not 86% on some of these exams, but all ~~**of**~~ the exams across all the subjects. It can speak all the languages, ~~**et**~~ ~~**cetera**~~, ~~**et**~~ ~~**cetera**~~. Humans in comparison ~~**and**~~ individual human is ~~**like**~~ super narrow. Humanity as a whole is more on the level of the AI, but that's one area in which the AI is ~~**like**~~ already pretty clearly superhuman. On the other hand, depth is still an advantage for the human AIs, sorry, the human experts, as opposed to the AIs. They're getting pretty good, but they're definitely not at the level of command of a subject ~~**like**~~ a human expert has.

00:09:30 
 Breakthrough insight, that's the same thing we just talked about with the Eureka moments. That is really, ~~**I**~~ ~~**would**~~ ~~**say**~~, humanity's biggest edge right now in comparison to AI systems. So ~~**I**~~ only give the AI a one on that dimension. AI is a lot faster. It can typically generate content faster than we can read it. So that's ~~**like**~~ a pretty notable threshold. We can't even keep up reading what it's able to write. And it's also way less expensive than a human.

00:09:57 
 And I typically say, you can expect it to be ~~**like**~~ at least 10 times faster and probably at least 10 times cheaper. It's also super available and parallelizable, meaning ~~**like**~~ it's on 24 seven. It can just sit there and do nothing until you come back to it and say, Hey, I have another question for you or whatever. And it doesn't cost anything to do that. It only costs something when you're using it. If you want to, you can also spend up 10 or a hundred at the same time, which obviously you can't do for humans. So these are probably AI's biggest advantage. Memory, as much as our memories are definitely very fallible and imperfect, our memories are definitely still way better than AI memories.

00:10:37 
 We have this sort of integrated sense of who we are, what we're doing, what our purpose is, what our long-term goals are, how what we're doing now fits into the big picture. That's all very intuitive for us. The more ~~**I**~~ study AI systems, the more impressed ~~**I**~~ am with human memory because today's batch of AI systems don't have that. They at best can ~~**like**~~ search on the internet and find stuff. Of course they know a lot internally. They have a good ~~**like**~~ long-term factual memory in some sense. But if they need to ~~**go**~~ query information on the fly, it's a rough, it's a brittle process. And they also have ~~**like**~~ finite working memory.

00:11:11 
 They're pretty good in that working memory, but outside of that, things start to get tough. I'm sure you guys have seen systems like RAG, retrieval augmented generation. ~~**Tell**~~ ~~**me**~~ ~~**if**~~ ~~**that's**~~ ~~**not**~~ ~~**a**~~ ~~**familiar**~~ ~~**term**~~ ~~**and**~~ ~~**I**~~ ~~**can**~~ ~~**go**~~ ~~**into**~~ ~~**that**~~ ~~**a**~~ ~~**little**~~ ~~**bit**~~, but that's just one of the ways that people are trying to improve AI memory. And it's very much a work in progress right now. Technology diffusion speed, this is going to be a big focus of the talk, actually. ~~**I**~~ ~~**think**~~ it's a big part of what you guys should be thinking about because humans are not great at learning new technologies, especially people who are mid and late career. They are going to be pretty reluctant in a lot of cases to embrace a new way of working. ~~**Of**~~ ~~**course**~~, ~~**everybody's**~~ ~~**heard**~~ ~~**the**~~ ~~**saying**~~, ~~**you**~~ ~~**can't**~~ ~~**teach**~~ ~~**an**~~ ~~**old**~~ ~~**dog**~~ ~~**new**~~ ~~**tricks**~~.

00:11:58 
 I think that is actually key to a lot of the opportunity that I see for young people entering the workforce to take advantage of AI in a way that their more senior coworkers may be, for whatever reason, not inclined or not able to do. ~~**AI**~~, ~~**on**~~ ~~**the**~~ ~~**other**~~ ~~**hand**~~, ~~**though**~~, does take advantage of this stuff really quickly. When somebody figures out a new way to do whatever, whether that's a new memory technique or a new optimization, something that makes it faster or something that makes training more efficient, whatever, these things spread super quickly because a lot of times it's like, ~~**Oh**~~, ~~**okay**~~, ~~**cool**~~. You found a way to ~~**opt**~~ to optimize the learning process. So it works 40% faster. I'll plug that into my system. ~~**Boom**~~. Now everybody can take advantage of that.

00:12:39 
 Broadly speaking, most of the research has been published. These days we are in a period of closing. So due to the fact that the human researchers are actually now sharing fewer of their breakthroughs, especially out of the top labs, like your open AIs, your anthropics and deep minds, the pace of diffusion in AI might be actually slowing a little bit, but it's still pretty fast. And here's one paper ~~**I**~~ ~~**can**~~ ~~**share**~~ ~~**this**~~ ~~**presentation**~~. Of course, if you want a sobering read, you might consider natural selection favors AIs over humans. That's ~~**a.**~~ ~~**That's**~~ ~~**like**~~ an academic paper. ~~**Okay**~~.

00:13:11 
 Bedside manner is another one. People often think you could never have an AI that could match the warmth or the empathy of a human. On the contrary, that's not really the case. The AIs are extremely patient. They are~~**,**~~ ~~**you**~~ ~~**can**~~ ~~**get**~~ ~~**them**~~ ~~**to**~~ ~~**behave**~~ ~~**weirdly**~~, but by default, they're ~~**like**~~ actually quite nice, quite patient, quite understanding, very willing to explain things to you. And indeed~~**,**~~ ~~**like**~~ we see this in the medical system. Doctors are overworked. They're stressed out.

00:13:35 
 They don't have time. but the chat bots, they'll explain things to you 10 times and they'll be polite every single time. So ~~**it's**~~, ~~**this**~~ ~~**is**~~ maybe a little bit of a radical position for me to give the AI a higher mark on bedside manner than humans, but certainly at least in some ways ~~**it**~~ ~~**is**~~ true. And then ~~**this**~~ final one, maybe alongside Breakthrough Insight is probably the biggest weakness of AI relative to humans. We are ~~**like**~~ broadly pretty robust to crazy stuff. If a crazy person comes up to you on the street, you get ~~**this**~~ quick sense, wait a second, I think I'm dealing with a crazy person here. If somebody is trying to scam you, the alarm bells go off pretty quick. Something about this doesn't seem quite right.

00:14:16 
 Your guard goes up and you're scrutinizing these inputs at a different level. AI systems don't really do that ~~**very**~~ well. So they're much easier to trick. We see all these ~~**like**~~ jailbreaks. We see them divulging information they're not supposed to divulge. We see chatbots on car dealer websites agreeing to $1 car sales. All these things are because AIs are not ~~**very**~~ adversarially robust. This ~~**even**~~ extends to ~~**pretty**~~ advanced, this is not just a chatbot phenomenon.

00:14:47 
 I'm sure I've heard of AlphaGo,  the AI that was ~~**like**~~ the world record best go player in history. It's broadly considered to be superhuman at playing go. And yet ~~**I**~~ ~~**recently**~~ ~~**did**~~ a podcast episode on this. If you want to learn more about it, it's from a group called far AI. They found a way to create an adversarial attack on alpha go and consistently defeat it with a strategy that a human would never lose to. ~~**I**~~ ~~**don't**~~ ~~**play**~~ ~~**Go**~~, so ~~**I**~~ ~~**don't**~~ ~~**know**~~ a lot about that, but they basically found that it has major blind spots. Even these superhuman Go players, when they're able to adversarially optimize against it, they were able to find ways to beat it. And again, ways that a human ~~**will**~~ ~~**look**~~ ~~**at**~~ ~~**that**~~ ~~**and**~~ ~~**be**~~ ~~**like**~~, you lost to that?

00:15:30 
 That's crazy. But the AIs just have these big blind spots. They are not adversarially robust. ~~**I**~~ ~~**think**~~ it's really important to keep these strengths and weaknesses in mind because you want to play to your strengths as a human, and you don't want to be competing with the AIs in the ways that they are superhuman. A lot of people cash this out to, and this is ~~**like**~~ the kind of advice that people mid-career are oftentimes getting these days, and including from me. You can think of an AI as a day one employee who's ~~**like**~~ pretty bright, eager, hardworking, but doesn't know anything about your business. Totally lacks context. ~~**Right**~~.

00:16:09 
 And can also make really weird mistakes. So you've got to be ~~**super**~~ careful to spell everything out for them, give them ~~**super**~~ clear directions, show them what good looks like. All these sorts of things. But basically if you do that, then you have infinite interns or in a coding CS type of context, people will say you have infinite entry level software developers. So that is ~~**like**~~ a radically different working environment that you guys are entering into as compared to anyone in human history, ~~**right**~~? ~~**Like**~~ never before did any software firm have anything where they could say, ~~**Oh**~~ ~~**yeah**~~, we have infinite junior coders, ~~**right**~~? Or we have infinite interns. That's never been a thing, but it is now starting to be a thing.

00:16:50 
 And I was just at a,~~**at**~~ an event not too long ago where people were like, yeah, we're not hiring as many junior coders anymore because we're really just focused on making our senior people more productive. And we think that with all these tools and the infinite interns that we can give them, that that's a more~~**,**~~ that's a more advantageous strategy for us. It's going to be higher ROI for our business. So I'm definitely not one to ~~**like**~~ sugarcoat things. I think this is a real challenge for a lot of people entering the workforce. You're now competing against infinite interns, infinite entry-level coders, and you want to make sure you are angling toward human strengths and away from AI strengths. ~~**Okay**~~. ~~**Three**~~, ~~**understand**~~ ~~**the**~~ ~~**modes**~~ ~~**of**~~ ~~**AI**~~ ~~**production**~~.

00:17:36 
 This is, I think there's just a ton of confusion. And so ~~**I**~~ ~~**like**~~ ~~**to**~~ try to clarify this for people. There's basically three ways that ~~**I**~~ see people working with AI systems today. One that's like very familiar is often called co-pilot mode. Microsoft uses that term for their product, but this is basically the chat GPT experience where you as the human are doing your thing. You might be doing your coding work. You might be doing. whatever you're doing, you might be writing a letter, you might be putting together an analysis, you might be brainstorming a list of things, but at some point you think, what ~~**I**~~ could do is ~~**I**~~ could ask AI for help.

00:18:09 
 And then you go over to it and you put in some instructions and it gives you something back and you can look at it in real time. And you ~~**think**~~, ~~**oh**~~ ~~**yeah**~~, that's good, bad, whatever. ~~**I**~~ ~~**can**~~ ~~**use**~~ ~~**it**~~. Maybe not. There's a couple of good ideas there. This is the real time back and forth mode where you are the pilot. It is the co-pilot. And ~~**I**~~ ~~**think**~~ this is definitely something, but you'll see one of my later things, ~~**like**~~ you want to get good at this.

00:18:29 
 This is only one of the three modes though. The other mode, which ~~**I**~~ ~~**think**~~ is actually going to be even more~~**.**~~ more important in some ways in business contexts, especially like big business contexts is what I call delegation mode. You could also call it task automation mode. And it is the idea where you're not just interacting real time ad hoc haphazard. Instead, you're saying, let's find some bottlenecks in our business. Let's find some things that ~~**Right**~~ ~~**now**~~, we have to put a lot of time and energy into, and maybe we really have to manage people very carefully to get the quality and consistency where we want it to be. And maybe this inbox is overflowing, and we're going to go hire a bunch more people to do this thing.

00:19:10 
 Or maybe we would like to 10x what we're doing. We ~~**just**~~ don't have the resources to do that. Identifying these sorts of tasks and then setting up a system for AI to do that and to do it consistently in the broader context of the business That's what I call delegation mode. And the key thing there is you want to get to the point where you are not evaluating every single AI output anymore. When you're doing co-pilot mode, you have to evaluate every single output~~**,**~~ ~~**right**~~? Nobody's going to~~**,**~~ ~~**you**~~ would be very unwise to just take the output of chat GPT and turn it in as your paper or turn it in as your coding assignment. There have been examples~~**,**~~ ~~**I'm**~~ ~~**sure**~~ ~~**you've**~~ ~~**seen**~~ ~~**them**~~, where lawyers have done that. They thought the chat GPT didn't make mistakes or whatever, and so they turned in a brief to the court.

00:19:52 
 And some of those guys I think have lost their license because that's just outright malpractice. You have to review what you're getting out of ~~**copilot**~~ mode. But if you do your setup right, then you can get to the point for many tasks where the AI can consistently do the task, and then you don't have to evaluate every single one anymore. You can get to the point where you actually can trust it. There's a trade-off there where you're dialing in, you're narrowing the scope, you're zooming in on a very particular problem, you're setting it up, you're controlling what the inputs are going to be, you're working through it, you're ~~**like**~~ testing a bunch of inputs to make sure that the outputs are what you want, and then at some point depending on ~~**like**~~ how important it is, how high risk it would be if it did make a mistake, at some point you can say actually this feels ~~**like**~~ good enough now that we can actually use this as a process in our business and not have to supervise it every single time. So that's delegation mode and that's going to come back again in a minute too. And then in the middle we have The~~**,**~~ ~~**the**~~ sort of missing middle is ~~**idea**~~ that the best of both worlds would be ~~**like**~~, if you could delegate in real time ~~**like**~~ you do in ~~**copilot**~~ mode, but you could trust the results ~~**like**~~ you ~~**can**~~ ~~**you**~~ ~~**can**~~ get to with work and delegation mode. This would be ~~**like**~~ the dream of agents ~~**right**~~ this would be ~~**like**~~ saying.

00:21:05 
 Hey, I just had this idea.  ~~**Oh**~~, ~~**by**~~ ~~**the**~~ ~~**way**~~, can you go out and find 20 websites of businesses that offer ~~**whatever**~~ accounting services in Detroit, Michigan, where I'm based and go look at the rates that they have and then put those into a spreadsheet and come back, write an analysis of all that and come back to me when it's done. The sort of mid-scale problem that you would give to a person. If you can do that on the fly and actually get good results back. Now we're into agent mode. And that's not quite there yet, but it is coming quite soon. The general consensus in the field is that the next big open AI release, whether that's GPT-5 or GPT-4.5 or whatever, is probably going to power a lot of those ~~**like**~~ multi-step, multi-app agent use cases. But that's not quite there yet, but ~~**I**~~ ~~**think**~~ it's pretty safe to say it's coming.

00:22:00 
 Okay. So those are the modes.  ~~**So**~~ just getting clear on~~**,**~~ ~~**on**~~ what mode you're actually using and being able to talk about that and have~~**,**~~ ~~**have**~~ conversations where you're helping other people understand what's going on. Having this conceptual framework in your head, ~~**I**~~ ~~**think**~~ it's super useful to do that. Very simple tip, but super important. Definitely use the best available AIs. If you're using free chat GPT, ~~**like**~~ you're not good enough, it's absolutely worth the $20 a month. And if you have to go do a Upwork project to get the $20 a month to do it, ~~**like**~~ again, it's absolutely worth it.

00:22:30 
 There's no reason really to use anything other than one of the top tier models. Top tier models today are ~~**Cloud**~~ ~~**3**~~, GPT-4. Actually, when I wrote this two days ago, ~~**Cloud**~~ ~~**3**~~ had taken the top position. I would now say GPT-4, which just released a new version. This goes to show how quick the leaderboard can change. Now, GPT-4, latest version, is probably top again. ~~**Cloud**~~ ~~**3**~~ is great. It's very good for writing.

00:22:55 
 And Gemini Advanced, Gemini 1.5, is also extremely good. ~~**And**~~ Google is ~~**very**~~ ~~**much**~~ a live player in this game. There are a couple of open source options that are decent, even very good. They're all very good compared to what we had even a year ago, but I tend to stick with the very best tools and I don't mess around ~~**too**~~ ~~**much**~~ with anything else. I basically use nothing other than these three tools. If you're ~~**gonna**~~ go into the open source, into hobbyist land, you also have to figure out where you're ~~**gonna**~~ run it. Like the very best open source models are also big, ~~**or**~~ you can ~~**run**~~ ~~**that**~~ ~~**on**~~ ~~**your**~~ ~~**laptop**~~. It's just a pain in the butt.

00:23:28 
 I would generally advise sticking with the best tools. This is ~~**by**~~ ~~**the**~~ ~~**way,**~~ ~~**also**~~ my advice to ~~**like**~~ business owners, buy the best tools for your team. Don't cheap out. Don't be a cheapskate. ~~**I**~~ ~~**would**~~ ~~**say**~~ ~~**for**~~ ~~**you**~~ ~~**guys**~~, don't work at a place that isn't willing to buy you the best tools ~~**either**~~. ~~**All**~~ ~~**right**~~. So now we get into the modes. Mastering co-pilot mode.

00:23:46 
 I think you guys are probably all well on your way here. ~~**I**~~ ~~**have**~~ ~~**a**~~ ~~**slide**~~ ~~**on,**~~ ~~**I**~~ ~~**should**~~ ~~**have**~~ ~~**actually**~~ ~~**shown**~~ ~~**this**~~ ~~**slide**~~ ~~**before.**~~ Everybody has different frameworks for prompting best practices. But they largely end up being the same. OpenAI has published their official guide to prompting. Anthropic has their official guide to prompting. ~~**I**~~ ~~**have**~~ ~~**my**~~ ~~**official**~~ ~~**guide**~~ ~~**to**~~ ~~**prompting.**~~ They're basically all saying the same thing.

00:24:09 
 It's you want to make sure your instructions are very clear. One of the great rewards, ~~**especially**~~ in a software environment of working with AIs is that it forces you to take a breath before ~~**just**~~, and I used to do this all the time. And I'm sure some of you do too. ~~**Oh**~~, I'm going to code code ~~**just**~~ immediately. I'm starting to type code class, whatever. And have I even thought about what I'm trying to do? I personally struggled with that in the past. Working with AIs helps me there because I can't expect the AI to do anything for me until I've articulated what I want and I have to do that pretty clearly or I'm going to get something in the general direction of what I want but not really what I want.

00:24:45 
 So everybody always is going to say you're going to need clear, accurate, unambiguous instructions. That's an art in and of itself, definitely something worth practicing, probably pretty clear to you guys already. The next big thing that is ~~**super**~~ important ~~**or**~~ ~~**super**~~ useful is ~~**especially**~~ if you have examples, some things are easier shown than told. So give it examples of what good looks like. In some ways, this is ~~**like**~~ the thing that has unlocked the current AI era. The GPT-3 paper title was large language models are few shot learners. Few shot learners means that if you give it a couple of examples, it can pick up on the task and it can begin to do the task. Even if you didn't describe the task, just based on the examples that it sees, that's a pretty profound thing.

00:25:28 
 Like no AI system before GPT-3 could ever do that. Certainly not in a general purpose way. So we're only ~~**like**~~ two years into the few shot ~~**in**~~ learning era and it's a huge advantage for many tasks instead of ~~**to**~~ try ~~**to**~~ tell it exactly what to do ~~**if**~~ ~~**this**~~ ~~**then**~~ ~~**that**~~ ~~**do**~~ ~~**this**~~ ~~**then**~~ ~~**that**~~ so often you can just be ~~**like**~~ here's the sample input here's what a good output looks like give it a few of those and you'll get much better results ~~**again**~~ ~~**i**~~ ~~**think**~~ ~~**this**~~ ~~**is**~~ ~~**probably**~~ ~~**fairly**~~ ~~**obvious**~~ ~~**so**~~ ~~**i**~~ ~~**don't**~~ ~~**want**~~ ~~**to**~~ ~~**waste**~~ ~~**too**~~ ~~**much**~~ ~~**time**~~ ~~**on**~~ ~~**prompting**~~ You can also get good results by telling it what role you want it to play. That can be ~~**like**~~ a professional role. You're the senior software engineer supervising my work, giving me feedback on it. Your job is to do a code review of my work, that kind of thing. You can also do specific names. Sometimes when the AIs write in a very ~~**like**~~ verbose, ~~**kind**~~ ~~**of**~~ flowery, wordy way, I'll tell it, I want you to ~~**think**~~ Einstein Hemingway.

00:26:21 
 That's my phrase. And then sometimes I'll also say, so Einstein Hemingway, that's your role. It's this mashup. I don't want ~~**super**~~ smart, but I also want terse, crisp, clear, simplest possible language. Sometimes I also say, we want to demonstrate our intelligence ~~**in**~~ ~~**part**~~ via economy of words. ~~**you'll**~~ ~~**get**~~ ~~**a**~~ ~~**very**~~ ~~**different**~~ ~~**style**~~ ~~**of**~~ ~~**writing**~~ ~~**out**~~ ~~**if**~~ ~~**you**~~ ~~**say**~~ ~~**you**~~ ~~**want**~~ Einstein Hemingway ~~**versus**~~ ~~**just**~~ ~~**letting**~~ ~~**it**~~ ~~**write**~~ ~~**in**~~ ~~**its**~~ ~~**normal**~~ ~~**default**~~ ~~**way.**~~ And I personally strongly prefer the Einstein Hemingway. Other simple things ~~**I'm**~~ ~~**sure**~~ ~~**you've**~~ ~~**seen**~~ ~~**before**~~, labeling your data, giving the model time to think, that's like chain of thought, explain your reasoning.

00:26:53 
 These days they tend to do that by default. You can also tell it ~~**like**~~ exactly how you want your answer formatted. Use the format and literally give it a template for how you want it to return information to you. Again, ~~**I**~~ ~~**imagine**~~ you guys have ~~**seen**~~ this sort of thing. So everybody has their different framework on prompting. You want to be good at this. When you get a job, likely your boss will not be good at this. Possibly they will, most of the time they won't.

00:27:19 
 So even though this stuff is ~~**like**~~ fairly basic, it is a huge advantage relative to not knowing how to do it. So just a relatively simple crash course on this kind of thing can be worth a huge amount in terms of the ROI return on, and not just money, but time, energy, ~~**like**~~ you'll just get way better results from AI. Now, AIs are also starting to get pretty good at this. This is the latest thing from Anthropic. They call it the meta prompt. Basically what you do here is go to a collab notebook that they provide and give it a prompt and it will give you ~~**like**~~ a way better prompt based on your initial prompt. So it's ~~**like**~~ a funny meta thing where the AIs are already starting to help us prompt. Crazy, but I've used this and it definitely really helps.

00:28:01 
 It flushes it out for you and you can read ~~**like**~~ all the detailed, more detailed instructions and you can start to refine them. You'd be ~~**like**~~, Oh, that's not exactly what I meant. Very useful. Also in co-pilot mode, definitely getting used to these coding assistants. I'm sure you guys have all used some or maybe all of these things. GitHub co-pilot is ~~**like**~~ the most common one. Codium AI, I think is a really interesting one that's lesser known, but they specifically focus on code integrity. So they help you generate unit tests.

00:28:27 
 They do all these sort of type checking things, all the things that ~~**like**~~ you get dinged on in your homework that you might also get dinged on in a code review in your job. Because ~~**like**~~ somebody with a stick up their ass is ~~**like**~~ telling you, Oh, you got to do this every time, whatever. And you're ~~**like**~~, Oh, do I really care? Whether that really matters is debatable and definitely depends on context, but that's what Codium is there to help you do. And it's quite good at it. ~~**I**~~ ~~**personally**~~ have never been great at that stuff. And so ~~**I**~~ really like Codium because it comes around and cleans up my mess and reminds me of the things that ~~**I**~~ should be doing that ~~**I**~~ wasn't doing. And Cursor is ~~**like**~~ the next evolution on Copilot where it's ~~**like**~~ an AI first coding environment.

00:29:02 
 How many of you guys have used Cursor ~~**just**~~ out of curiosity? No Cursor users? ~~**Oh**~~ ~~**my**~~ ~~**God**~~. Okay, get Cursor. Definitely try it. It blows people's minds with how helpful it is. ~~**OK**~~, ~~**cool**~~. If you get nothing else out of this, you should all go try cursor.

00:29:17 
 Obviously, you're going to want to watch out in copilot mode for hallucinations and other mistakes. AI makes mistakes. It makes a lot ~~**less**~~ mistakes than it used to. It's probably going to continue to make fewer mistakes in the future, but it does still make mistakes. ~~**OK**~~, next one. Distinguishing yourself with delegation mode. I have a whole presentation here on AI task automation 101. This is something that ~~**I**~~ ~~**think**~~ young people entering the workforce can literally blow their bosses minds with and even crack into places that you might not otherwise be able to crack into by doing a little project like this and demonstrating to them what's possible because people ~~**don't**~~ ~~**these**~~ the reason these are tips ~~**because**~~ people do not understand the state of the art ~~**they**~~ do not understand the relative strengths and weaknesses ~~**if**~~ ~~**you**~~ ~~**have**~~ ~~**that**~~ and then you can bring some task automation to them and show them what's possible.

00:30:06 
 A lot of times they will,~~**they'll**~~ be literally mind blown by what is possible. And the fact that you can do it, they're going to look at you like you have magic powers. So we don't have time for the whole task automation thing, but it's often done with no code platforms. If you guys, many of you are in CS, like you shouldn't have any trouble using these no code platforms, but one thing to really understand about organizations, like how businesses really work, is that a lot of times their processes are not documented and not really formal at all. There is a way that work gets done, but nobody ~~**like**~~ actually sat down and designed that with a flow chart. So that's why I say in this presentation, these process diagrams do not exist. You guys may remember this person does not exist. It was just ~~**like**~~ a classic One of the early, early nerd AI things you can go to thispersondoesnotexist.com and it just makes a new person for you on every page load.

00:30:57 
 This is from, I think, a GAN, like a generative adversarial network that just makes headshots. And all these people are fake and it's ~~**like**~~ a mind blowing, wow, this is style GAN too is making all these things. ~~**So.**~~ ~~**Whatever**~~, that's an aside. This isn't a sort of reference to that, but the key thing to understand is businesses have implicit processes. Nobody really designed it in a lot of cases. Nobody really documented it, but just one person knows I do this and then I hand it off to them and then they do something and then it goes wherever. And people know where they fit and they know what their responsibility is.

00:31:30 
 They don't necessarily have command of the bigger picture. So a lot of what you have to do to be successful is map out these processes. ~~**They**~~ ~~**exist**~~, ~~**they**~~ ~~**exist**~~ implicitly, but there's ~~**no**~~, ~~**nobody's**~~ ~~**ever**~~ ~~**really.**~~ ~~**Gotten**~~ specific about ~~**like**~~, how ~~**actually**~~ do we do this? So just understanding that ~~**that's**~~ the state of play and you're going to probably have to go figure that out and map out this territory and figure out what are the inputs? What are the outputs? What's happening in between ~~**whose**~~ responsibility is it? I use these terms, input logic and outputs for the AI portion, but then there's also, when does it happen?

00:32:03 
 What causes the process to start?  What happens at the end of the process? All of these things are~~**,**~~ ~~**you**~~ ~~**have**~~ ~~**to**~~ answer these questions. If you do that, and then you find one of my other little best practices is prompt before app. What I mean by that is the first thing you want to do is understand what this core task is and demonstrate that the AI can do it. Work on the prompt, make sure the inputs and outputs are working. Work with whoever ~~**kind**~~ ~~**of**~~ owns the process to say, give me 10 inputs and 10 examples of what good looks like. And let me see if I can match that with the AI.

00:32:35 
 And if I can do that,~~**and**~~ ~~**possibly**~~ ~~**by**~~ ~~**the**~~ ~~**way,**~~ you might just take their 10 examples and use them as few shot examples and just say, Hey AI, here's nine. Can you do the 10th? ~~**and**~~ ~~**just**~~ ~~**see**~~ maybe that's enough. It can often be quite simple. Sometimes it takes more work. Each case is different. But if you can get that ~~**working**~~, ~~**then**~~ you can do all this other stuff with the no-code platforms and the triggers and the automations and Zapier, and maybe you have to write a little custom code at some point in the Zapier Zap to get it to work. But if you can get that core thing to work, ~~**then**~~ you can build the process around it.

00:33:03 
 You can pipe it into where it needs to go. ~~**you**~~ ~~**will**~~ blow people's minds. ~~**I**~~ ~~**think**~~ this is going to be one of the most common new AI jobs is just automating existing processes with AI. And these are not ~~**like**~~ sexy things a lot of times. They're things that nobody really wants to do. Write the first draft. And sometimes there may still be a human in the loop as well. Maybe it's just like, we get a ton of customer service tickets.

00:33:27 
 Nobody really enjoys answering those tickets.  ~~**Can**~~ ~~**you**~~ ~~**write**~~ the first version of the response to the tickets? Here's like a hundred examples of what we've done in the past. If you can get that to work though, in an environment where nobody else knows how to do that, you are immediately a difference maker. And that can open doors into context where you're going to have remarkable access to expertise, because these people do have something that they're bringing to the table, but it's not AI task automation. And they will love you for it if you can actually bring this and make it work for them. And one of the reasons they're going to love it is it's going to be a lot faster and it's going to be a lot cheaper than having a human do it. ~~**So**~~ ~~**I'll**~~ ~~**put**~~, ~~**while**~~ ~~**I'm**~~ ~~**thinking**~~ ~~**about**~~ ~~**it**~~, ~~**I'll**~~ ~~**just**~~ ~~**drop**~~ ~~**these**~~.

00:34:05 
 Links into the chat and my chat go. There it is. So there's that presentation. And then this one as well. ~~**All**~~ ~~**right**~~, ~~**cool**~~. So ~~**there's**~~ ~~**more**~~ ~~**question**~~, ~~**please**~~. SPEAKER_03: You're from right here. ~~**Okay**~~.

00:34:22 
 It's a coming through because I'm like far away. SPEAKER_00: It's ~~**a**~~ little choppy. Yeah. Speak up. But yeah. SPEAKER_03: That's what I was asking ~~**like**~~ whether the audio is fine but from back there, but I did have one question, ~~**what**~~ a lot of the time people in ~~**in**~~ their degree and CS right now they're doing a bunch of data structures type stuff and it's all ~~**what**~~ ~~**is**~~ ~~**the**~~ ~~**stock**~~ ~~**what**~~ ~~**is**~~ ~~**the**~~ ~~**queue**~~ ~~**like.**~~ ~~**all**~~ ~~**that**~~ ~~**sort**~~ ~~**of**~~ ~~**thing**~~ and ~~**chow**~~ ~~**gbt**~~ and ai tools are really good they understand a lot of that already ~~**i**~~ ~~**feel**~~ ~~**like**~~ there's this gap between what most students are spending a lot of their time on in classes and ~~**like**~~ all the stuff that you're talking about ~~**it's**~~ ~~**all**~~ new ~~**it's**~~ ~~**like**~~ how to but none of this is in universities ~~**i**~~ ~~**guess**~~ my question to you is given the fact that you've talked you've spoken with people in industry what do you think the right balance is ~~**is**~~ ~~**it**~~ ~~**like**~~ just stop, just do the bare minimum for school? Or ~~**is**~~ ~~**it**~~ ~~**like**~~ 50-50?

00:35:11 
 Does that kind of make sense?

SPEAKER_00: ~~**Yeah,**~~ ~~**it's**~~ ~~**a**~~ ~~**good**~~ ~~**question.**~~ School's ~~**a**~~ ~~**little**~~ ~~**fucked**~~ ~~**up,**~~ ~~**to**~~ ~~**be**~~ ~~**honest,**~~ ~~**in**~~ ~~**a**~~ ~~**lot**~~ ~~**of**~~ ~~**cases.**~~ In the real world, there's no~~**,**~~ ~~**I'm**~~ ~~**a**~~ ~~**simultaneously,**~~ ~~**I'm**~~ ~~**a**~~ believer that there's no world more real than the one you're living in right now. It's not~~**,**~~ there's ~~**some**~~ ~~**like**~~ mythical real world out there that's totally different. But in the work for pay world, which is definitely different from school, nobody cares about using chat GPT. There are maybe a few ~~**like**~~ idiosyncratic people out there who are purists or who have extreme data security issues. There are a few legitimate reasons to think that you should never use a certain tool like this.

00:35:51 
 Even then you can, I would say data concerns are fairly overblown and there are ways to use these tools that protect your data privacy, but. ~~**By**~~ ~~**and**~~ ~~**large**~~, people just want the job done. They want it done well, they want it done fast. And if you can deliver that and AI is part of that recipe, then that's a win. So ~~**I**~~ ~~**don't**~~ ~~**really**~~ ~~**know**~~ what that means for school. ~~**I**~~ ~~**would**~~ ~~**not**~~, it's hard to give advice. ~~**Cause**~~ ~~**like**~~ you need to pass your classes. We're not in ~~**a**~~ ~~**actually**~~ ~~**hell**~~ ~~**you**~~ ~~**could**~~ ~~**drop**~~ ~~**out**~~.

00:36:21 
 And if you're sweet at AI,~~**there's**~~ ~~**there's**~~ infinite opportunity ~~**Like**~~ the AI world does not care ~~**if**~~ ~~**you**~~ ~~**have**~~ a degree, if you ~~**could**~~ automate tasks effectively. ~~**I**~~ ~~**do**~~ ~~**believe**~~ ~~**that**~~ there is a lot of opportunity that is increasingly independent of a degree, but I'm not telling you to drop out. And if you're not going to drop out, you should pass your classes. And if your classes have ~~**like**~~ final exams that involve do this programming task and you're not allowed to use AI, then ~~**I**~~ ~~**think**~~ that's a little retro, but it is the reality. And so you ~~**got**~~ ~~**to**~~ ~~**do**~~ ~~**it**~~, but I don't code by hand really ~~**any**~~ ~~**more**~~ at all. I pretty much only go to an AI, describe what I want.

00:37:01 
 Sometimes I will curate context. So I might bring ~~**like**~~ documentation from something that I'm using, or I might, if it's a code base that I'm already working in, I might copy one class in and another class in and be ~~**like**~~, Hey, I want to make a new method that does this. I don't want to implement the caching pattern from over here or whatever. And it's a much better typer than I am. And frankly, a better coder as well. But the typing alone, it ~~**like**~~ saves a ton of time just to have it generated quickly. So yeah, I don't really, not knowing enough about the specifics of the context of the classes and the requirements, whatever, I can't say with confidence, ~~**like**~~ ignore this or don't, or don't do that. But I will say, generally speaking, people don't care if you're using AI.

00:37:47 
 They want, the classic thing is ~~**like**~~ good, fast and cheap. You can only pick two. And AI is starting to break that paradigm. Or another way to say that is ~~**of**~~ ~~**course**~~, ~~**like**~~ good, fast and cheap will be redefined. So you can still only pick two, but. Relative to traditional good, fast and cheap. You can only pick two with AI. ~~**I**~~ ~~**feel**~~ ~~**like**~~ ~~**I**~~ routinely deliver good, fast and cheap and people don't have to pick.

00:38:11 
 And if you can deliver that people will love you for it. And nobody's really~~**,**~~ ~~**Oh**~~, it's cheating to use chat GPT. No, nobody has that. Very few have that attitude. And ~~**I**~~ ~~**probably**~~ ~~**wouldn't**~~ work at that sort of place because. Unless there's a really good reason, like we're a military contractor or whatever, you can come up with reasons. But unless there's a really good reason, ~~**like**~~ ~~**we're**~~ ~~**a**~~ ~~**military**~~ ~~**contractor**~~ ~~**or**~~ ~~**whatever**~~, ~~**you**~~ ~~**can**~~ ~~**come**~~ ~~**up**~~ ~~**with**~~ ~~**reasons**~~. But unless there's a really good reason, if it's just ~~**like**~~ the boss doesn't like it or something, then ~~**I**~~ ~~**would**~~ ~~**be**~~ ~~**like**~~, ~~**eh**~~, this is. ~~**Yeah**~~, that's great.

00:38:35 
 Thank you. You bet. Another thing,~~**by**~~ ~~**the**~~ ~~**way**~~, this is like the easiest thing in the world, but in so many organizations right now would~~**.**~~ radically change how they do things. ~~**Clawed**~~ ~~**for**~~ ~~**sheets**~~. It's just ~~**a**~~ integrated API call that you~~**,**~~ ~~**that**~~ ~~**they've**~~ wrapped up into a typical spreadsheet function. And it's ~~**fucking**~~ amazing. It can structure data for you.

00:38:57 
 It can answer questions for you.  ~~**It**~~ can fill in gaps in data. ~~**It**~~ can do all sorts of things that you might want to do. And it takes two seconds to install. And especially with their cheap version, it's ~~**like**~~ insanely cheap too. They even have a caching layer in there. It's all~~**,**~~ ~~**it's**~~ an extremely useful tool. And this is like 0.1% of businesses have probably installed Cloud for Sheets right now.

00:39:20 
 If you literally just went in and were ~~**like**~~, Hey, if we thought about using Cloud for Sheets, ~~**yeah**~~. What's that? Nobody will know. And it's ~~**like**~~ an, it's immediate alpha. ~~**Okay**~~. Mindful of time. Scout all applications. I describe myself as an AI scout.

00:39:32 
 I literally spend all my time trying new stuff, reading research, trying to understand what's going on from all angles. Definitely find it remarkable how often people ~~**just**~~ can't be bothered to try a new thing. The fact that all of you, that nobody raised their hand for cursor is a little bit of a warning sign for that. Go try some of these new things. There's an AI app for everything these days. ~~**And.**~~ Anytime I have an unfamiliar task that I haven't really done in a while, whether it's like making slides, for example, or these slides actually predate Gamma getting quite good, but Gamma.app is a really good little slide maker now. If I'm editing video, Descript has all sorts of cool AI tools for helping to edit video.

00:40:15 
 Suno and this other one, Udio,make unbelievably sick music. Listen to this. Hold on one second. Did I share my sound? Okay. Listen to this. This is AI. SPEAKER_01: ~~**I**~~ ~~**don't**~~ ~~**know**~~ ~~**about**~~ ~~**you**~~, but it's getting good enough that ~~**I**~~ ~~**actually**~~ ~~**would**~~ listen to it.

00:40:49 
 SPEAKER_00: for just enjoyment of music.~~**Like**~~ ~~**it's**~~ ~~**not**~~ ~~**even**~~ ~~**just**~~ ~~**a**~~ ~~**novelty**~~ ~~**anymore.**~~ The lyrics are honestly pretty good too. My favorite part is when it goes to deep minds and ~~**it's**~~, this was made by a friend of mine, but I asked him, did you ask for that? And he said, no, ~~**I**~~ ~~**basically**~~ ~~**just**~~ ~~**did**~~ ~~**nothing.**~~ And ~~**that's**~~ ~~**it.**~~ ~~**I**~~ ~~**just**~~ ~~**gave**~~ ~~**it**~~ ~~**a**~~ ~~**quick**~~ ~~**prompt.**~~ ~~**It**~~ ~~**took**~~ ~~**no**~~ ~~**effort.**~~

00:41:08 
 So it's definitely worth going out and trying a lot of these new products. There's a million of them popping up all the time. And ~~**it's,**~~ ~~**again,**~~ ~~**it's**~~ something that other people won't do. And ~~**it's**~~ ~~**something,**~~ ~~**it's**~~ ~~**certainly**~~ ~~**something**~~ ~~**that**~~ ~~**like**~~ mid and late career people won't do. So ~~**it's**~~ ~~**something**~~ ~~**that**~~ you with your~~**,**~~ ~~**your**~~ youthful energy can go out and do ~~**that.**~~ Other people will find ~~**like**~~ remarkable ~~**that**~~ you do ~~**that.**~~ So ~~**I**~~ ~~**think**~~ ~~**it's**~~ an extremely easy way to get an edge and you can just ~~**again,**~~ routinely blow people's minds. ~~**I'm**~~ ~~**sure**~~ ~~**you**~~ ~~**guys**~~ ~~**are**~~ ~~**familiar**~~ ~~**with**~~ ~~**Repl.it**~~ ~~**at**~~ ~~**least**~~ ~~**somewhat.**~~

00:41:39 
 Their Ghostwriter product is pretty cool.  Watch that space because ~~**I**~~ ~~**think**~~ they're going to have a lot more stuff coming soon. I've been trying Julius recently. It's another ~~**kind**~~ ~~**of**~~ coding, real-time coding thing. I gave it a prompt earlier today. Maybe I could just show ~~**this**~~ how easy this was. I just went to it and said I wanted to ~~**Yeah**~~. ~~**Okay**~~.

00:42:00 
 Look how easy this was. I wanted to get audio ~~**of**~~ ~~**off**~~ a video, simple as that, but all I had was the YouTube URL. So I said, can you fetch the audio from a YouTube video and give me an MP3? It wrote the code, executed the code, gave me a download link, worked flawlessly. First time, no problem. Amazing. This now, why would I do this instead of chat GPT? First of all, I'm not sure if chat GPT would do it.

00:42:25 
 It may or may not refuse me. So that's one issue. ~~**Second**~~, ~~**Chess**~~ ~~**UBD**~~ ~~**can**~~ ~~**execute**~~ ~~**code**~~, ~~**but**~~ ~~**it's**~~ ~~**a**~~ ~~**little**~~ ~~**bit**~~, ~~**this**~~ ~~**is**~~ ~~**like**~~ ~~**even**~~ ~~**more**~~ ~~**robust**~~ ~~**code**~~ ~~**execution**~~ ~~**as**~~ ~~**part**~~ ~~**of**~~ ~~**the**~~ ~~**process**~~. ~~**If**~~ ~~**you**~~ ~~**went**~~ ~~**to**~~ ~~**Claude**~~, ~~**it**~~ ~~**might**~~ ~~**write**~~ ~~**you**~~ ~~**this**~~ ~~**code**~~, ~~**but**~~ ~~**then**~~ ~~**you'd**~~ ~~**still**~~ ~~**have**~~ ~~**the**~~ ~~**question**~~ ~~**of**~~ ~~**like**~~, ~~**where**~~ ~~**am**~~ ~~**I**~~ ~~**going**~~ ~~**to**~~ ~~**execute**~~ ~~**this**~~ ~~**code**~~? ~~**And**~~ ~~**maybe**~~ ~~**that's**~~ ~~**no**~~ ~~**problem**~~ ~~**for**~~ ~~**you**~~. ~~**Cause**~~ ~~**you've**~~ ~~**got**~~ ~~**like**~~ ~~**development**~~ ~~**environments**~~ ~~**all**~~ ~~**over**~~ ~~**the**~~ ~~**place**~~, ~~**whatever**~~ ~~**other**~~ ~~**people**~~ ~~**don't**~~. The ability to just go ~~**do**~~ ~~**this**~~ in a browser and get this done in 15 seconds. How much of a pain in the ass would this be?

00:42:50 
 I'm sure you've seen Devin as well. Who's seen Devin? ~~**Couple**~~ ~~**hands**~~. Okay, cool. ~~**Yeah**~~. Devin is ~~**a.**~~ Coding agent where it actually, this is the beginning of the agent moment. From what I've heard, I haven't used it yet, but from~~**,**~~ ~~**cause**~~ ~~**it's**~~ ~~**like**~~ ~~**still**~~ ~~**wait-listed**~~, but from what I've heard, it's ~~**like.**~~ Getting good, but not quite good yet, but it's~~**,**~~ you can start to see how it's happening.

00:43:09 
 It will actually hit a bug,~~**not**~~ ~~**know**~~ ~~**what**~~ ~~**to**~~ ~~**do**~~. Go to the documentation online, read the documentation, come back and try to fix the bug based on reading the documentation. It's starting to run this actual loop process of ~~**just**~~ keep going. ~~**Just**~~ ~~**cause**~~ ~~**I**~~ ~~**failed**~~ ~~**doesn't**~~ ~~**mean**~~ ~~**I'm**~~ ~~**done**~~. ~~**Just**~~ ~~**the**~~ ~~**person**~~ ~~**I'm**~~ ~~**not**~~ ~~**going**~~ ~~**to**~~ ~~**just**~~ ~~**give**~~ ~~**up**~~ ~~**because**~~ ~~**I**~~ ~~**hit**~~ ~~**a**~~ ~~**first**~~ ~~**bug**~~, ~~**like**~~ ~~**I**~~ ~~**got**~~ ~~**to**~~ ~~**keep**~~ ~~**going**~~. ~~**I**~~ ~~**got**~~ ~~**to**~~ ~~**try**~~ ~~**something**~~ ~~**else**~~. ~~**I**~~ ~~**got**~~ ~~**to**~~ ~~**go**~~ ~~**find**~~ ~~**some**~~ ~~**new**~~ ~~**information**~~. ~~**I**~~ ~~**got**~~ ~~**to**~~ ~~**find**~~ ~~**another**~~ ~~**approach**~~.

00:43:30 
 Maybe I got to change my plan. That's what ~~**Devon**~~, and there's also an open ~~**Devon**~~, which you can go download and run on your own environment. Another one coming soon will be magic.dev. ~~**Brush**~~ ~~**past**~~ ~~**that**~~ ~~**for**~~ ~~**now**~~ ~~**because**~~ ~~**nobody**~~ ~~**really**~~ ~~**knows**~~ ~~**what**~~ ~~**it**~~ ~~**is**~~ ~~**other**~~ ~~**than**~~ ~~**that**~~ ~~**it's**~~ ~~**allegedly**~~ ~~**a**~~ ~~**huge**~~ ~~**deal**~~. ~~**Okay**~~. ~~**Almost**~~ ~~**there**~~. And then I can do a couple of questions. ~~**I**~~ ~~**think**~~ ~~**I've**~~ ~~**covered**~~ ~~**most**~~ ~~**of**~~ ~~**it**~~.

00:43:49 
 This evals expert concept is pretty similar to Or it's at least intimately related to delegation mode, but it can apply in a lot of contexts. But basically, ~~**is**~~ this AI thing working? How would we know if it's not working or if something changes and it's not working as well as it used to be? What are the ~~**like**~~ things that we want it to always do? What are the things that we want it to never do? And how are we sure that it's always never doing that~~**,**~~ ~~**right**~~? It becomes quite challenging. So setting up~~**,**~~ this is basically like a unit testing type of thing, except you're doing it potentially on an ongoing basis for all the inputs and outputs of these systems.

00:44:26 
 And this can really help you ~~**like**~~ assure yourselves and assure ~~**like**~~ the company that you're working with that. This is actually working, ~~**right**~~? And we have visibility into what's happening and we can quantify. We said we never want it to do X. As of right now, we're seeing that it is doing X 3% of the time. Is that tolerable? Is that intolerable? That ~~**obviously**~~ it depends on context.

00:44:49 
 There's going to be judgment calls to be made, but you need to have ~~**those**~~ ability to describe what is actually happening in order to have an informed discussion. So these are sometimes called benchmarks and it's a set of evals and benchmarks are the same thing. Benchmarks are more ~~**like**~~ public evals ~~**tend**~~ ~~**to**~~ ~~**be**~~ ~~**again**~~, the same thing, but more internal. I'll show you an example of ~~**a.**~~ ~~**of**~~ ~~**a**~~ one at Waymark really quick. What account is this in? Excuse me. It's not in this account. This one also ties to Cloud 3, so it'll be your Cloud for Sheets.

00:45:23 
 So it's worth a real quick look if I can find it super quick. OK, this is for Waymark. We have an AI write video scripts and We have all these things that we want it to do and not do, and you ~~**don't**~~ ~~**have**~~ ~~**to**~~ ~~**worry**~~ ~~**about**~~ ~~**the**~~ ~~**details**~~ ~~**of**~~ ~~**this**~~ ~~**too**~~ ~~**much**~~. But here's the sort of thing that you can do. Let's say, for example, we give the AI a template for a video, and its job is to write a script that fits that template. I've installed Cloud for Sheets here. That's what I'm using. I use the meta prompt to help flesh out all these instructions.

00:45:57 
 And now I'm going to give it a script structure that was the input to the AI and then the output. And what I want to check in this particular eval is, are you using, and we serve small businesses, so these are all ~~**like**~~, so we want to confirm that they're using, that the AI is using the business contact information in the same way that it's being used in the original script. Because if they put it in the wrong place, the videos end up looking weird and whatever. So this is a highly idiosyncratic problem. A lot of this stuff is going to be idiosyncratic. The businesses you guys are going to work at are all going to be very idiosyncratic. Everybody has their own weird ~~**shit**~~. And nobody likes looking at this stuff to sit there and say, ~~**oh**~~, ~~**hey**~~, can you go through a hundred of these and check to see if the AI did ~~**any**~~ contact information in the wrong place?

00:46:42 
 People hate that kind of work.  ~~**Super**~~ tedious, ~~**super**~~ time consuming. That also means it's expensive and people aren't very good at it because it just gets ~~**super**~~ boring and their minds go elsewhere. And just in every way it sucks. This is ~~**like**~~ definitely the perfect job for AI. So here's what that looks like ~~**that**~~ we have a JSON structure. Who cares? It doesn't really matter.

00:46:58 
 And now I'm literally just calling the cloud for sheets function and saying, here is this. Full script. This was just my template instruction. I actually now put the variables here. So you can see the variables are now populated and now we're calling ~~**to**~~ ~~**Claude**~~ and it's going to tell us at the end of the thing, are there any places where contact information is incorrectly used? I had to workshop this for a while to get it to work, but here you have it. Okay. This is the expected answer.

00:47:28 
 So we're like actually testing in this phase that~~**,**~~ ~~**that**~~ it~~**,**~~ ~~**that**~~ Claude can do the job, but now we're going to start to use it on all of the stuff that we do so we can monitor. How often do we see that the AI script has contact information in the wrong place? So here ~~**it's**~~, oh, expert hair regeneration. But here we have, oh, in the actual one that it wrote, it gave a URL. That~~**,**~~ according to our rules, is a violation. So boom, it flags it. Here's another example of that. This one, there was one, it had call today with a phone number, but in the one that it wrote, it didn't have any contact information.

00:48:00 
 So that's a violation in our rules. We get to define our rules. That's a violation going the other way. In this one, there weren't ~~**a**~~ violation. So it's just told to return true, it returns true. So anyway, all this is to say, Being a person who can set up these evals to quantify what is happening. ~~**Oh**~~, ~~**you**~~ want to make sure that our AI is never doing this. ~~**Okay**~~, ~~**cool**~~.

00:48:20 
 Here's a, let's set up a framework. It can be as simple as ~~**called**~~ ~~**for**~~ sheets. There are way more advanced and complicated tools out there, but a simple ~~**call**~~ ~~**for**~~ sheets where it's give me five examples of where it's doing it. And five examples of where it's doing it wrong. I'll use the meta prompt. I'll workshop the prompt. I'll set it up. I'll be able to demonstrate that it can evaluate things accurately.

00:48:38 
 And then we can use that going forward. However we want. That is another skill that people don't even have their heads wrapped around what they need. So if you can understand how to use ~~**evals**~~ and actually develop them, you're going to be ~~**like**~~ a unicorn in 99% of businesses in the country today. ~~**OK**~~, I'm going to land the plane here because I know we're just about at time. You're going to be the one that knows this. The mid-career and late-career people are not. They're going to have expertise~~**,**~~ ~~**of**~~ ~~**course**~~, that you're not going to have.

00:49:05 
 But I think you really want to position yourself as somebody who understands this stuff and can help lead them through understanding what they don't know. These can be really basic questions like, what are the new jobs that~~**,**~~ ~~**that**~~ are~~**,**~~ ~~**that**~~ companies are hiring for in AI? There is this concept of the AI engineer. If you haven't heard that, look that up. ~~**Cause**~~ that's ~~**kind**~~ ~~**of**~~ software engineering, but with a heavy AI emphasis, it's like a software engineer that can really use the AI tools and models well, and actually build models into products. The ML ops specialist is like fine tuning models, curating data sets, some of this benchmarking and eval type stuff. And then the AI implementation specialist is ~~**like**~~ a little less technical. And by the way, these are all very much in flux and businesses call them different things~~**,**~~ ~~**whatever**~~.

00:49:50 
 These are just kind of things that ~~**I**~~ ~~**observe**~~. This would be somebody who's, ~~**Oh**~~, I'm going to help ~~**us**~~ ~~**like**~~ set up an internal chat bot that ~~**like**~~ has access to our database or has access to all of our knowledge base. So we can ~~**like**~~, so here's a super simple example. I work with a company that has a thousand employees. They just wanted to set up a simple chat so that people can ask AI their day-to-day questions instead of having to go ask a person. They have a whole team that sits there and answers questions for the thousand employees. And now they're ~~**like**~~ able to shift ~~**like**~~ half of that work to AI. AI doesn't know all the answers, but we gave it 250 documents.

00:50:21 
 And we just, it's a very simple thing to set that up with ~~**a**~~ off the shelf product. I literally just used chatbase.co for that one, load the documents in. ~~**couldn't**~~ ~~**be**~~ ~~**easier**~~, but just knowing how to set that kind of stuff up is a job unto itself these days. I call that AI implementation. Also, ~~**I**~~ ~~**think**~~ sometimes it really helps to have these simple mantras for people. At Waymark, I say, AI or die. You're never going to. And I also say, done for you beats do it yourself.

00:50:47 
 Or if it used to be,make your own video. You had to write all the copy. Now the AI writes it for you. It's a 10 times better experience. So having these little mantras that people can wrap their heads around when they're very unfamiliar with the technology really helps. Three general ones that ~~**I**~~ ~~**say**~~ are summary, not strategy, meaning ~~**like**~~ this ~~**kind**~~ ~~**of**~~ goes back to the eureka moments. A lot of times business leaders will be ~~**like**~~, can I have this thing help me with business strategy? And ~~**I**~~ always tell them, no, that's unfortunately that's still on you.

00:51:15 
 You can have it do a lot of routine stuff, repetitive stuff, ~~**the**~~ ~~**stuff**~~, ~~**the**~~ work that nobody wants to do, or the work that you'd like to scale, but you can't. That stuff it can do, but it can't do your business strategy. Similarly, process not product. Whatever it is in your business that is like your unique product, don't delegate that to the AI. Delegate all the other stuff to the AI that sucks to do, ~~**right**~~? Or that's at least like not that awesome to do. But whatever makes you super special, hold on to that. Double down on that as humans and use AI in ~~**like**~~ all the other places.

00:51:46 
 Again, convert not create, right? These are just ~~**kind**~~ ~~**of**~~ simple ways that you can communicate to people ~~**like**~~ what the AI is good for and what it's not really so good for ~~**this**~~ ~~**may**~~ ~~**change**~~, and that leads us to the last thing which is just continue to update your understanding continue to update your~~**,**~~ ~~**your**~~ world model on this. ~~**couple**~~ ~~**years**~~ ~~**into**~~ ~~**AI.**~~ ~~**I**~~ ~~**would**~~ ~~**say**~~ ~~**really**~~ we're just one year into AI. GPT-4 was really the moment when it went from not that useful to ~~**like**~~ often very useful to a naive user. That's only been one year. So The systems are still going to get a lot better. The state of the art is going to change.

00:52:25 
 The tail of the cognitive tape is going to change. All this stuff is going to happen. It's going to continue to evolve. So just keep in mind ~~**like**~~ we are nowhere near a static fixed end state right now. You're going to have to keep evolving with it and follow people that because this is definitely a community thing~~**,**~~ ~~**right**~~? Going back to the breadth on the tail of the cognitive tape, the AIs are bigger than us in ~~**very**~~ profound ways. They know more than us. They can speak all the languages.

00:52:49 
 So they can do, because they are so big, the surface area is so vast. It takes a community to understand what is going on. Even a full year after GPT-4 was released, people are still finding better ways to prompt it that are bringing out new state of the art. So this is a very short list, but these are people, ~~**obviously**~~ myself, but people that I really highly recommend specifically for coding. This dude, McKay Wrigley on Twitter posts super good demos. There's quite a few ~~**like**~~ him. Another one that I really respect a lot is Swicks on Twitter and his podcast is called Latent Space. He also has a blog, really good content.

00:53:26 
 And if you are like less into coding, but more into just ~~**kind**~~ ~~**of**~~ general business and knowledge work, then ~~**I**~~ ~~**think**~~ the number one ~~**commenter**~~ commentator in today's world is a guy named Ethan Malik. He's a professor at Wharton and super prolific, just came out with a book. And you're like, if there's one ~~**like**~~ business school professor that your future boss will maybe have heard of, it might be this guy. So it would definitely be a good one for you to know about too. And ~~**I**~~ ~~**like**~~ these people, ~~**I**~~ ~~**trust**~~ to have good content. There's a lot of AI snake oil out there these days ~~**of**~~ 99% of people are using chat GPT wrong ~~**by**~~ ~~**my**~~ ~~**course**~~. Don't buy that course. All ~~**this**~~ ~~**stuff**~~, all the real information you need is free.

00:54:00 
 And it's like freely available from good thought leaders ~~**by**~~ ~~**the**~~ ~~**products**~~ ~~**by**~~ GPT four. Don't buy ~~**the**~~ ~~**like**~~. ~~**See**~~ prompting secrets. ~~**Cause**~~ ~~**they're**~~ ~~**not**~~, there's not really any prompting secrets you can't get for free. ~~**All**~~ ~~**right**~~. ~~**Sorry**~~ ~~**to**~~ ~~**go**~~ ~~**a**~~ ~~**little**~~ ~~**long**~~. Happy to do a couple ~~**questions**~~ and then I can get you on with your evening. I don't hear anything.

00:54:19 
 If anybody wants to ask a question, either speak up or step up. SPEAKER_04: Can you tell me something about ~~**like**~~ how AI is used in finance ~~**stocks**~~, ~~**like**~~ in the finance sector a little bit? SPEAKER_00: Yeah, to be honest, it's not an area I know a ton about. And a big reason for that is that a lot of it is held much more closely and proprietary as trade secret in finance than in other areas. This is actually something I just heard Swick say the other day. He was like, in finance, everybody is keeping everything a secret. Whereas in~~**,**~~ ~~**in**~~ ~~**like**~~ software, people are sharing methods. ~~**So**~~, and open sourcing stuff all over the place.

00:54:58 
 So they're certainly like high frequency trading has been an AI game for years. And ~~**I'm**~~ ~~**not**~~ ~~**sure**~~ how much language models are breaking into ~~**like**~~ highly quantitative finance. Those tend to be ~~**like**~~ speed is really super important in finance, especially for trading style finance. So those systems tend to be ~~**like**~~ much more narrowly focused versus the ~~**like**~~ broad purpose AIs that are dominating the news today. Bloomberg tried to train their own model based on all the proprietary data that they had. And they found that GPT-4 was better, even though they had all this special data and all the~~**,**~~ ~~**whatever**~~ ~~**that**~~ they thought this would give us an advantage ~~**in**~~ ~~**the**~~ ~~**end**~~, still, they found GPT-4 was better. So that's an interesting data point. ~~**I**~~ ~~**think**~~ there's also~~**,**~~ ~~**there's**~~ a finance is obviously a huge thing~~**,**~~ ~~**right**~~?

00:55:50 
 You could also think about the mortgage industry ~~**is**~~ ~~**like**~~ part of finance. ~~**I**~~ ~~**think**~~ there's definitely a ton of opportunity for. language models to do ~~**like**~~ document review. Is this, are these documents in order? Is anything missing? Does anything seem wrong? There's ~~**like**~~ a lot of ~~**kind**~~ ~~**of**~~ task automation work that you could do there. Underwriting has been checklist, anything where there's ~~**like**~~ a checklist, ~~**right**~~?

00:56:12 
 Did the person submit this? Did the person correctly fill this form out? Did this~~**,**~~ ~~**does**~~ this match with this and this other form? All of those sorts of things are probably going to, those are ~~**like**~~ ways in which finance is ~~**like**~~ similar to other business. And in that way, ~~**I**~~ ~~**think**~~ that'll happen in finance just like it happens in other places. But the more sort of trading you get, the more it's like a lot of hedge fund and big bank secrets. SPEAKER_02: Where can I go to find more information on setting up my own AI to train on? Say I had a lot of data and results from people that took action on that data.

00:56:49 
 I wanted to train an AI to do that. SPEAKER_00: ~~**I**~~ ~~**mean**~~, it depends on how much data you have and it depends on how technical you want to get. You are going to be almost for sure limited to fine tuning because the amount of data that it takes to train a model from scratch. ~~**And**~~ ~~**here**~~ ~~**I'm**~~ ~~**referring**~~ ~~**again**~~ ~~**to**~~ ~~**general**~~ ~~**purpose**~~ ~~**language**~~ ~~**models**~~. If you're talking about narrow~~**,**~~ ~~**you**~~ ~~**know**~~, you can train a linear regression. That's a model in some sense. You can train a really simple thing with very little data, but assuming we're talking about ~~**like**~~ relatively general purpose language model type things. They take a huge amount of data to train from scratch.

00:57:25 
 So you're going to be much more likely fine tuning one. And there are the easiest way to do it would be to use the open AI platform. They have a fine tuning API. You can~~**,**~~ it doesn't cost much ~~**couple**~~ ~~**bucks**~~, typically like a hundred examples is enough. If you want to just do one task, but one of the things to realize about fine tuning is that they've trained these models. Like it's ~~**a.**~~ high art to train these chatbots to handle everything in the way that they do. Tons of trade-offs, tons of data to get it to say no to the things that it's supposed to say no to and do the things it's supposed to do. And there's a ton that goes into that.

00:58:05 
 Fine-tuning is relatively easy if you are narrowing down to one task. So with Waymark, for example, we do fine tune GPT 3.5 to be our script writer. And we have hundreds of examples. The quality of the data is probably the most important thing, because that's what your model is learning from. If there are mistakes in there, it's going to learn those mistakes. So you really need to have high quality data. That ~~**again,**~~ comes back to the~~**,**~~ ~~**the**~~ evals ~~**are**~~ really important there. How do I know what's high quality?

00:58:32 
 I might define a bunch of rules as to what's high quality. And then I have to actually examine all the things with all those rules in mind. Maybe ~~**I**~~ ~~**can**~~ help with that. So~~**.**~~ ~~**I**~~ would say keep in mind you're going to be fundamentally narrowing the scope of what the system can do when you fine tune it. It is possible to fine tune in a way that can do more than one task. Standard starting place would be like a few hundred examples, maybe even fewer than that. Could be a few tens of examples to start.

00:58:57 
 Probably you're to really get good performance. ~~**You**~~ ~~**might**~~ ~~**need**~~ a few hundred. If it's a hard task or there's a lot of edge cases or whatever, ~~**you**~~ ~~**might**~~ ~~**need**~~ a few thousand, but somewhere in that range is enough to do reasonably good fine tuning on the open AI platform. And ~~**you**~~ just need to assemble high quality data and run it through. ~~**You**~~ ~~**can**~~ ~~**also**~~ ~~**do**~~ ~~**that**~~ open source. ~~**You**~~ ~~**could**~~ get a LLAMA model or any number of open source models with techniques that are generally called PEFT, P-E-F-T, parameter efficient fine tuning. Basically what they do, ~~**you've**~~ ~~**heard**~~ ~~**of**~~ ~~**course**~~, ~~**like**~~ GB3 has 175 billion parameters, whatever. That's ~~**like**~~ a lot to mess with.

00:59:36 
 Today's models are smaller. You might have a LLAMA model that's ~~**a**~~ 7 billion. That's still a lot to mess with. If you use parameter efficient fine-tuning, basically most of those are just held in place constant, and then just like 3% of them or whatever are ~~**chained**~~ changed to fine-tune it just to do whatever you want it to do. You can run that in a Google collab notebook and ~~**could**~~ ~~**be**~~ ~~**like**~~ very limited compute requirements. So techniques there are called ~~**Laura**~~, ~~**Q**~~ ~~**Laura**~~. Those are examples of parameter efficient fine tuning. ~~**I**~~ ~~**think**~~ ~~**Laura**~~ ~~**is**~~ ~~**like**~~ ~~**low**~~ ~~**rank**~~, ~~**something**~~ ~~**low**~~ ~~**rank**~~, meaning it's like not changing that much of the matrices.

01:00:15 
 Yeah, that's a pretty good start.  ~~**That'll**~~ ~~**take**~~ ~~**you**~~ ~~**pretty**~~ ~~**far.**~~ Just know that when you do it, you're gonna be narrowing what it can do. If you bring it a hundred examples of writing a script, and then you come ask it to write you a recipe for a birthday cake or whatever, it literally can't do it. It's lost that ability entirely. Now, ~~**like**~~ our Waymark script writer can only write scripts. It can do nothing else. That's in a way good because we don't want it to do anything else, but it's in a way bad because if you think that ~~**I'm**~~ ~~**gonna**~~, ~~**I've**~~ ~~**tried**~~ ~~**to**~~ ~~**train**~~ ~~**a**~~ ~~**model**~~ ~~**to**~~ ~~**write**~~ ~~**as**~~ ~~**me**~~, And oh, this is a good tip, actually, ~~**also**~~, ~~**too**~~.

01:00:47 
 So I have this podcast. I do an intro essay for each podcast. ~~**I**~~ ~~**literally**~~ write one page and I read it. After doing that a bunch of times, I started to think, ~~**man**~~, maybe I could fine tune a model to write ~~**as**~~ me. Very hard to do. I write a lot of different things. It's tough. What works ~~**a**~~ ~~**lot**~~ better is taking 30 of my essays, dropping them into cloud three and then saying, use the style of all these essays and write me something new.

01:01:11 
 and then it will do a much better job. So in a lot of cases, you may think you need fine tuning. You really don't. You just need to give the AI a lot of examples. Every case is different. So just keep in mind that ~~**like**~~ fine tuning is not always the answer. And especially ~~**I**~~ ~~**find**~~ ~~**that**~~ software engineers want to go to more technical solutions often than are really necessary. If ~~**I**~~ ~~**were**~~ ~~**to**~~ ~~**go**~~ ~~**talk**~~ ~~**to**~~ a software engineer and say ~~**like**~~, how can I get AI to write as me?

01:01:35 
 They're going to immediately be like,~~**Oh,**~~ let's fine tune. Let's~~**,**~~ ~~**let's**~~ do this. We could use Laura. We could use this Pafta~~**,**~~ ~~**blah**~~, ~~**blah**~~, ~~**blah**~~. The actual best answer today is~~**.**~~ Give cloud three~~**,**~~ a ton of examples and have it do it. And it's going to beat any fine tuning you're going to do. Keep that in mind.

01:01:51 
 SPEAKER_02: Thank you. SPEAKER_03: Thank you so much for the talk. SPEAKER_00: ~~**I**~~ ~~**just**~~ go out there and establish yourselves as the AI experts that these dinosaurs will never become. And they will love you for it. ~~**They're**~~, this is something that ~~**it's**~~ ~~**on**~~ ~~**the**~~, ~~**it's**~~ ~~**on**~~ ~~**the**~~ infinite interns ~~**is**~~ ~~**like**~~, ~~**it's**~~ ~~**on**~~ ~~**the**~~ horizon. It's here. It's not quite here, but you're in a moment where if you can establish ~~**that**~~ you're the person to go to for this kind of technology ~~**there**~~, everybody's ~~**all**~~ the business leaders are going to be looking for that. The next talk I'm giving is a group of business leaders that are ~~**all**~~ ~~**like**~~, mid and late career, they're ~~**all**~~ worth millions of dollars, but they're ~~**all**~~ asking these questions.

01:02:30 
 So if you can answer these questions for them, then they will hire you. SPEAKER_03: Awesome. Thank you ~~**so**~~ much. SPEAKER_00: My pleasure ~~**guys**~~. Have a great evening. ~~**I**~~ ~~**hope**~~ this was helpful. ~~**Yeah**~~. ~~**For**~~ ~~**now**~~.

